#!/usr/bin/env python3
"""
æµ‹è¯•å¢å¼ºç‰ˆè¯­ä¹‰åˆ†æ®µå™¨
"""

import time
from src.core.enhanced_semantic_segmenter import EnhancedSemanticSegmenter
from src.core.sentence_transformer_model import SentenceTransformerModel
from src.core.text_type_detector import TextTypeDetector
from src.utils.text_processor import TextProcessor


def test_enhanced_segmenter():
    """æµ‹è¯•å¢å¼ºç‰ˆåˆ†æ®µå™¨"""
    
    print("ğŸš€ åˆå§‹åŒ–å¢å¼ºç‰ˆè¯­ä¹‰åˆ†æ®µå™¨...")
    
    # åˆå§‹åŒ–ç»„ä»¶
    try:
        sentence_model = SentenceTransformerModel("sentence-transformers/all-MiniLM-L6-v2")
        text_processor = TextProcessor()
        type_detector = TextTypeDetector()
        enhanced_segmenter = EnhancedSemanticSegmenter(sentence_model, text_processor, type_detector)
        
        print("âœ… ç»„ä»¶åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # æµ‹è¯•æ–‡æœ¬
    test_texts = [
        {
            "name": "æŠ€æœ¯æ–‡æ¡£",
            "text": """
            Pythonæ˜¯ä¸€ç§å¼ºå¤§çš„ç¼–ç¨‹è¯­è¨€ï¼Œå…·æœ‰ç®€æ´çš„è¯­æ³•å’Œä¸°å¯Œçš„åº“ç”Ÿæ€ç³»ç»Ÿã€‚å®ƒå¹¿æ³›åº”ç”¨äºWebå¼€å‘ã€æ•°æ®ç§‘å­¦å’Œäººå·¥æ™ºèƒ½é¢†åŸŸã€‚
            
            æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒåˆ†æ”¯ï¼Œé€šè¿‡ç®—æ³•è®©è®¡ç®—æœºä»æ•°æ®ä¸­å­¦ä¹ æ¨¡å¼ã€‚æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œæ¥å¤„ç†å¤æ‚çš„æ•°æ®ç»“æ„ã€‚
            
            BERTæ¨¡å‹æ˜¯åŸºäºTransformeræ¶æ„çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚å®ƒåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œç‰¹åˆ«æ˜¯åœ¨æ–‡æœ¬åˆ†ç±»å’Œé—®ç­”ç³»ç»Ÿä¸­ã€‚
            
            APIè®¾è®¡æ˜¯è½¯ä»¶å¼€å‘çš„é‡è¦ç¯èŠ‚ã€‚RESTful APIæä¾›äº†æ ‡å‡†åŒ–çš„æ¥å£è®¾è®¡æ–¹å¼ï¼Œä½¿å¾—ä¸åŒç³»ç»Ÿä¹‹é—´èƒ½å¤Ÿæœ‰æ•ˆåœ°è¿›è¡Œæ•°æ®äº¤äº’ã€‚
            """
        },
        {
            "name": "å°è¯´æ–‡æœ¬",
            "text": """
            å¤•é˜³è¥¿ä¸‹ï¼Œè§è–°å„¿ç«™åœ¨å±±é¡¶ä¸Šï¼Œç›®å…‰çœºæœ›ç€è¿œæ–¹çš„äº‘æµ·ã€‚å¾®é£è½»æŠšè¿‡å¥¹çš„é•¿å‘ï¼Œå¸¦æ¥é˜µé˜µèŠ±é¦™ã€‚
            
            "è§ç‚å“¥å“¥ï¼Œä½ è¿˜è®°å¾—å°æ—¶å€™æˆ‘ä»¬åœ¨è¿™é‡Œè®¸ä¸‹çš„è¯ºè¨€å—ï¼Ÿ"å¥¹è½»å£°è¯´é“ï¼Œå£°éŸ³ä¸­å¸¦ç€ä¸€ä¸é¢¤æŠ–ã€‚
            
            è¿œå¤„çš„å¤©ç©ºä¸­ï¼Œä¸€ç¾¤å¤§é›æ­£å‘å—é£å»ã€‚å®ƒä»¬çš„é¸£å«å£°åœ¨å±±è°·ä¸­å›è¡ï¼Œæ˜¾å¾—æ ¼å¤–æ‚ è¿œã€‚è–°å„¿çš„çœ¼ä¸­é—ªçƒç€æ³ªå…‰ï¼Œé‚£æ˜¯å¯¹è¿‡å¾€å²æœˆçš„çœ·æ‹ã€‚
            
            æ—¶å…‰èè‹’ï¼Œå½“å¹´çš„å°‘å¹´å¦‚ä»Šå·²ç»æˆé•¿ä¸ºé¡¶å¤©ç«‹åœ°çš„ç”·å­æ±‰ã€‚ä½†é‚£ä»½åˆå¿ƒï¼Œé‚£ä»½çœŸæŒšçš„æ„Ÿæƒ…ï¼Œä¾ç„¶å¦‚å½“åˆä¸€èˆ¬çº¯å‡€ã€‚
            """
        }
    ]
    
    print(f"\nğŸ“ å¼€å§‹æµ‹è¯• {len(test_texts)} ä¸ªæ–‡æœ¬æ ·æœ¬...")
    
    for i, sample in enumerate(test_texts, 1):
        print(f"\n{'='*60}")
        print(f"æµ‹è¯• {i}: {sample['name']}")
        print('='*60)
        
        start_time = time.time()
        
        try:
            # æ‰§è¡Œå¢å¼ºç‰ˆåˆ†æ®µ
            result = enhanced_segmenter.segment_text_enhanced(sample['text'])
            
            processing_time = time.time() - start_time
            
            if "error" in result:
                print(f"âŒ åˆ†æ®µå¤±è´¥: {result['error']}")
                continue
            
            # æ˜¾ç¤ºç»“æœ
            print(f"ğŸ“Š åˆ†æ®µç»“æœ:")
            print(f"   æ£€æµ‹æ–‡æœ¬ç±»å‹: {result['text_type']} (ç½®ä¿¡åº¦: {result['type_confidence']:.3f})")
            print(f"   åŸå§‹å¥å­æ•°: {result['sentence_count']}")
            print(f"   åˆ†æ®µè¾¹ç•Œæ•°: {result['boundary_count']}")
            print(f"   ç”Ÿæˆæ®µè½æ•°: {len(result['paragraphs'])}")
            print(f"   å¤„ç†æ—¶é—´: {processing_time:.3f}ç§’")
            
            print(f"\nğŸ“š åˆ†æ®µå†…å®¹:")
            for j, para in enumerate(result['paragraphs'], 1):
                print(f"\næ®µè½ {j} [{para['type']}]:")
                print(f"   å†…å®¹: {para['text'][:100]}{'...' if len(para['text']) > 100 else ''}")
                print(f"   é•¿åº¦: {para['length']} å­—ç¬¦, {para['sentence_count']} å¥")
                if para['key_phrases']:
                    print(f"   å…³é”®è¯: {', '.join(para['key_phrases'])}")
            
            print(f"\nğŸ“ˆ è´¨é‡è¯„ä¼°:")
            quality = result['quality']
            print(f"   ç»¼åˆè´¨é‡åˆ†æ•°: {quality['quality_score']:.3f}")
            print(f"   è¯­ä¹‰ä¸€è‡´æ€§: {quality['semantic_consistency']:.3f}")
            print(f"   ç»“æ„åˆç†æ€§: {quality['structure_score']:.3f}")
            print(f"   æ®µè½ç±»å‹åˆ†å¸ƒ: {quality['type_distribution']}")
            
        except Exception as e:
            print(f"âŒ å¤„ç†å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    test_enhanced_segmenter()